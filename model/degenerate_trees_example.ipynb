{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "degenerate_trees_example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CY-nXM_iUmA"
      },
      "source": [
        "# Degenerate Trees Example\n",
        "\n",
        "We only need numpy for the heavy lifting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a7FdejnfiqL"
      },
      "source": [
        "import itertools\n",
        "import dataclasses\n",
        "import pprint\n",
        "from typing import List\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3bWmvLfig1i"
      },
      "source": [
        "*An* implementation of an optimizer for degenerate trees. **Note** this (serial grid search) is by far the simplest implementation and one should expect far better performance from a more sophisticated algorithm (e.g. simulated annealing)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWpcuRjkZG2l"
      },
      "source": [
        "@dataclasses.dataclass\n",
        "class ModelInfo:\n",
        "  # The threshold applied to the target variable copied from the invocation to\n",
        "  # _optimal_coeffs. \n",
        "  cutoff: float\n",
        "\n",
        "  # The number of rows in the dataset greater than cutoff.\n",
        "  num_gt: int\n",
        "\n",
        "  # The number of rows in the dataset less than or equal to the cutoff.\n",
        "  num_lte: int\n",
        "\n",
        "  # The set of thresholds that maximizes the F1 across the dataset.\n",
        "  parameter_thresholds: List[float]\n",
        "\n",
        "  # The number of votes needed to maximize the F1 across the dataset.\n",
        "  vote_threshold: int\n",
        "\n",
        "  # The F1 from the optimal set of thresholds.\n",
        "  f1: float\n",
        "\n",
        "  # The omission error from the optimal set of thresholds.\n",
        "  omission_error: float\n",
        "\n",
        "  # The commission error from the optimal set of thresholds.\n",
        "  commission_error: float\n",
        "\n",
        "\n",
        "def _optimal_coeffs(\n",
        "    x: np.ndarray, y: np.ndarray, threshold: float,\n",
        "    stops: List[List[float]]) -> ModelInfo:\n",
        "  \"\"\"Determines an optimal set of thresholds and votes to predict y > threshold.\n",
        "\n",
        "  Performs a parameter sweep over the last dimension of x using the \n",
        "  cross-product of stops as thresholds in an attempt to predict y > threshold.\n",
        "\n",
        "  This will return the collection of elements from the last dimension of stops\n",
        "  and vote threshold over x that yields the highest F1 score in predicting y.\n",
        "\n",
        "  Args:\n",
        "    x: an array of shape [N, M, COLS_N] describing the dataset of thresholdable\n",
        "      columns (where thresholds are chosen from stops).\n",
        "    y: an array of shape [N] which is the target variable to be predicted by the\n",
        "      intersection of thresholds on x.  \n",
        "    stops: a list of length M * COLS_N containing lists of thresholds to sweep\n",
        "      over x (referencing the row-major last two dimensions in x).\n",
        "\n",
        "  Returns:\n",
        "    A tuple of a list of length M * COLS_N of selected stops, the selected\n",
        "    number of votes, the best F1 score, and the omission and commission error\n",
        "    of the selected candidate (ModelInfo).\n",
        "  \"\"\"\n",
        "  y = y > threshold\n",
        "  num_gt = np.sum(y)\n",
        "  num_lte = np.sum(~y)\n",
        "\n",
        "  vote_sweep_array = np.expand_dims(\n",
        "      np.linspace(1, x.shape[1], x.shape[1]), axis=0)\n",
        "  y = np.expand_dims(y, axis=-1)\n",
        "\n",
        "  best_model = None\n",
        "  for candidate in itertools.product(*stops):\n",
        "    candidate_array = np.reshape(np.array(candidate), [x.shape[1], x.shape[2]])\n",
        "    votes_per_row = np.sum(np.all(x > candidate_array, axis=-1), axis=-1)\n",
        "    \n",
        "    votes_cross_totals = np.tile(np.expand_dims(votes_per_row, axis=1), \n",
        "                                 [1, x.shape[1]])\n",
        "    vote_sweep = votes_cross_totals >= vote_sweep_array\n",
        "    tp = np.sum(np.logical_and(vote_sweep, y), axis=0)\n",
        "    fp = np.sum(np.logical_and(vote_sweep, ~y), axis=0)\n",
        "    fn = np.sum(np.logical_and(~vote_sweep, y), axis=0)\n",
        "    f1_all = tp / (tp + 0.5 * (fp + fn))\n",
        "\n",
        "    vote_thresh = np.argmax(f1_all) + 1\n",
        "    f1 = f1_all[vote_thresh - 1]\n",
        "\n",
        "    if (best_model is None) or (f1 > best_model.f1):\n",
        "      selected_tp = tp[vote_thresh - 1]\n",
        "      selected_fp = fp[vote_thresh - 1]\n",
        "      selected_fn = fn[vote_thresh - 1]\n",
        "\n",
        "      best_model = ModelInfo(\n",
        "          cutoff=threshold,\n",
        "          num_gt=num_gt,\n",
        "          num_lte=num_lte,\n",
        "          parameter_thresholds=candidate,\n",
        "          vote_threshold=vote_thresh,\n",
        "          f1=f1,\n",
        "          omission_error=selected_fn / (selected_tp + selected_fn),\n",
        "          commission_error=selected_fp / (selected_tp + selected_fp))\n",
        "\n",
        "  return best_model\n",
        "\n",
        "\n",
        "def cutoff_sweep(\n",
        "    x: np.ndarray, y: np.ndarray, x_stops: List[List[float]],\n",
        "    y_stops: List[float]) -> List[ModelInfo]:\n",
        "  \"\"\"Computes the optimal threshold stops for x given a sweep over y.\n",
        "\n",
        "  Args:\n",
        "    x: an array of shape [N, M, COLS_N] describing the dataset of thresholdable\n",
        "        columns (where thresholds are chosen from stops).\n",
        "    y: an array of shape [N] to be thresholded to a binary variable.\n",
        "    x_stops: a list of length M * COLS_N containing lists of thresholds to sweep\n",
        "        over x (referencing the row-major last two dimensions in x).\n",
        "    y_stops: a list of thresholds to sweep over y.\n",
        "\n",
        "  Returns:\n",
        "    A list of tuples for each of the thresholds in y_stops consisting of: a\n",
        "    tuple of a list of length M * COLS_N of selected stops, the selected number\n",
        "    of votes, the best F1 score, and the omission and commission error of the\n",
        "    selected candidate of columns in x that best predict the thresholded value\n",
        "    in y (ModelInfo)\n",
        "  \"\"\"\n",
        "  return [_optimal_coeffs(x, y, threshold, x_stops) for threshold in y_stops]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01i5swe8i51t"
      },
      "source": [
        "Lets test on some fake data. We'll use an ensemble of 2 degenerate trees with some arbitrary stops on [0, 1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-_iACIeZUPC"
      },
      "source": [
        "# Note that stops do not need to be in sorted order.\n",
        "\n",
        "# These apply to the values from the first tree.\n",
        "a_stops = [0, 0.1, 0.5, 0.6]\n",
        "b_stops = [0.3, 0.4, 0.9, 0.95]\n",
        "\n",
        "# These apply to the values from the second tree.\n",
        "c_stops = [0.2, 0.4, 0.7]\n",
        "d_stops = [0.1, 0.8]\n",
        "\n",
        "parameter_stops = [a_stops, b_stops, c_stops, d_stops]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVpNt5w8k1JX"
      },
      "source": [
        "Run the model on some fake data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otyzS--jZZU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58884ec-88c0-413b-81fd-e7b886c8eafc"
      },
      "source": [
        "# We've got 20 rows x 2 trees x 2 variables per tree.\n",
        "#\n",
        "# Note that for a given row in our example:\n",
        "#     [0, 0] is visited by a_stops for the first tree.\n",
        "#     [0, 1] is visited by b_stops for the first tree.\n",
        "#     [1, 0] is visited by c_stops for the second tree.\n",
        "#     [1, 1] is visited by d_stops for the second tree.\n",
        "\n",
        "test_x = np.random.uniform(size=[20, 2, 2])\n",
        "\n",
        "# This part is easy, just 20 random values.\n",
        "\n",
        "test_y = np.random.uniform(size=[20])\n",
        "\n",
        "# Find the optimal stops for our pair of degenerate trees!\n",
        "\n",
        "model_results = cutoff_sweep(\n",
        "    test_x,\n",
        "    test_y,\n",
        "    parameter_stops,\n",
        "    # We test 2 stops for y, and will therefore get 2 models out the other end.\n",
        "    [0.3333, 0.6666])\n",
        "\n",
        "pprint.pprint(model_results)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ModelInfo(cutoff=0.3333, num_gt=14, num_lte=6, parameter_thresholds=(0, 0.3, 0.7, 0.1), vote_threshold=1, f1=0.8125, omission_error=0.07142857142857142, commission_error=0.2777777777777778),\n",
            " ModelInfo(cutoff=0.6666, num_gt=7, num_lte=13, parameter_thresholds=(0.5, 0.3, 0.7, 0.1), vote_threshold=1, f1=0.5555555555555556, omission_error=0.2857142857142857, commission_error=0.5454545454545454)]\n"
          ]
        }
      ]
    }
  ]
}